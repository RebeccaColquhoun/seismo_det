{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1. Downloading Continuous Data\n",
    "\n",
    "The following will download the information on the stations that are available based on your search criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "json_basepath = os.path.join(os.getcwd(),\"json/station_list.json\")\n",
    "\n",
    "from EQTransformer.utils.downloader import makeStationList\n",
    "\n",
    "makeStationList(json_path=json_basepath, client_list=[\"SCEDC\"], min_lat=35.50, max_lat=35.60, min_lon=-117.80, max_lon=-117.40, start_time=\"2019-09-01 00:00:00.00\", end_time=\"2019-09-03 00:00:00.00\", channel_list=[\"HH[ZNE]\", \"HH[Z21]\", \"BH[ZNE]\"], filter_network=[\"SY\"], filter_station=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function will generate station_list.json file containing the station information. Next, you can use this file and download 1 day of data for the available stations at Ridgecrest, California from Southern California Earthquake Data Center or IRIS using the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EQTransformer.utils.downloader import downloadMseeds\n",
    "\n",
    "downloadMseeds(client_list=[\"SCEDC\", \"IRIS\"], stations_json=json_basepath, output_dir=\"downloads_mseeds\", min_lat=35.50, max_lat=35.60, min_lon=-117.80, max_lon=-117.40, start_time=\"2019-09-01 00:00:00.00\", end_time=\"2019-09-03 00:00:00.00\", chunk_size=1, channel_list=[], n_processor=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will download the continous data (in MiniSeed) and save them into individual folders for each station insider your defined output directory (i.e. downloads_mseeds).\n",
    "\n",
    "Check the downloading.ipynb or API Documentations for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2. Detection and Picking\n",
    "\n",
    "To perform detection & picking you need a pre-trained model of EQTransformer which you can get from ModelsAndSampleData.\n",
    "\n",
    "EQTransformer provides two different option for performing the detection & picking on the continuous data:\n",
    "\n",
    "Option (I) using pre-processed data (hdf5 files):\n",
    "This option is recommended for smaller periods (a few days to a month). This allows you to test the performance and explore the effects of different parameters while the provided hdf5 file makes it easy to access the waveforms.\n",
    "\n",
    "For this option, you first need to convert your MiniSeed files for each station into 1-min long Numpy arrays in a single hdf5 file and generated a CSV file containing the list of traces in the hdf5 file. You can do this using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EQTransformer.utils.hdf5_maker import preprocessor\n",
    "\n",
    "preprocessor(preproc_dir=\"preproc\", mseed_dir='downloads_mseeds', stations_json=json_basepath, overlap=0.3, n_processor=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will generate one station_name.hdf5 and one station_name.csv file for each of your stationâ€™s data and put them into a directory named mseed_dir+_hdfs. Then you need to pass the name of this directory (which contains all of your hdf5 & CSV files) and a model to the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EQTransformer.core.predictor import predictor\n",
    "\n",
    "predictor(input_dir= 'downloads_mseeds_processed_hdfs', input_model='EqT_model.h5', output_dir='detections', detection_threshold=0.3, P_threshold=0.1, S_threshold=0.1, number_of_plots=100, plot_mode='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use relatively low threshold values for the detection and picking since EQTransformer is robust to false positives. Note that enabling uncertainty estimation, outputting probabilities, or plotting all the detected events will slow down the process.\n",
    "\n",
    "Outputs for each station will be written in your output directory (i.e. detections).\n",
    "\n",
    "X_report.txt contains the processing info on input parameters used for the detection &picking and final results such as running time, the total number of detected events (these are unique events and duplicated ones have been already removed).\n",
    "\n",
    "X_prediction_results.csv contains detection & picking results.\n",
    "\n",
    "In the figures folder, you can find the plots for some detected events:\n",
    "    These plots are helpful to check if you are getting too many false positives (non-earthquake signals) and get a better sense that if your selected threshold values for the detection and picking is too high or too low.\n",
    "\n",
    "If you are using local MiniSeed files you can generate a station_list.json by supplying an absolute path to a directory containing Miniseed files and a station location dictionary using the stationListFromMseed function like the following:\n",
    "\n",
    "Option (II) directly from mseed files:\n",
    "You can perform the detection & phase picking directly on downloaded MiniSeed files. This saves both preprocessing time and the extra space needed for the hdf5 file and is recommended for larger (longer) datasets. However, it can be more memory intensive. So it is better to have your MiniSeed fils being shorter than one month or so.\n",
    "\n",
    "This option also does not allow you to estimate the uncertainties, save the prediction probabilities, or use the advantages of having hdf5 files which makes it easy to access the raw event waveforms based on detection results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3. Visualizing the Results\n",
    "\n",
    "Continouty of the Seismic Data Being Processed:\n",
    "Both prepocessor and mseed_predictor output a time_tracks.pkl file that contains the time info of original data and their number of components. You can use this file to visualize the continuity and type of your data using the following module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EQTransformer.utils.plot import plot_data_chart\n",
    "\n",
    "plot_data_chart('time_tracks.pkl', time_interval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helicorder Plots:\n",
    "To check if you are missing too many events (high false negative) in the continuous data or catch most of them, it is always a good idea to check out the raw data (the most important lesson in observational seismology). You can do it using these commands:\n",
    "\n",
    "First, you can check one particular day of (raw) data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EQTransformer.utils.plot import plot_detections, plot_helicorder\n",
    "\n",
    "plot_helicorder(input_mseed='downloads_mseeds/CA06/GS.CA06.00.HHZ__20190902T000000Z__20190903T000000Z.mseed', input_csv=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the following command will mark those events that you have detected on your helicorder plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_helicorder(input_mseed='downloads_mseeds/CA06/GS.CA06.00.HHZ__20190902T000000Z__20190903T000000Z.mseed', input_csv='detections/CA06_outputs/X_prediction_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4. Phase Association\n",
    "\n",
    "After detection, the following performs a simple and fast association and writes down the results in HypoInverse format (Y2000.phs) and ObsPy QuakeML format (associations.xml) which can directly be used to locate the detected earthquakes using conventional location algorithms like HypoInverse or NonLinLoc. This also outputs traceName_dic.json, a dictionary where the trace names for source waveforms of all the detections associated with an event are listed. This can be used later to access the original waveform traces for calculating the cross-correlations during the relocation process or magnitude estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "from EQTransformer.utils.associator import run_associator\n",
    "\n",
    "out_dir = \"asociation\"\n",
    "try:\n",
    "        shutil.rmtree(out_dir)\n",
    "except Exception:\n",
    "        pass\n",
    "os.makedirs(out_dir)\n",
    "\n",
    "run_associator(input_dir='detections', start_time=\"2019-09-01 00:00:00.00\", end_time=\"2019-09-03 00:00:00.00\",  moving_window=15, pair_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that unlike the predictor, mseed_predictor, and downloader modules the associator does not automatically generate the output directory and you need to create it first. Otherwise, it will write the output files in the current directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
