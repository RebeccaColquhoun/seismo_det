{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca00fa0c",
   "metadata": {},
   "source": [
    "TODO: need to rewrite this to get arou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15317b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c160ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import util\n",
    "import pickle\n",
    "from obspy import UTCDateTime\n",
    "import obspy\n",
    "import matplotlib\n",
    "from matplotlib.patches import Rectangle\n",
    "import scipy\n",
    "from spectrum import *\n",
    "import matplotlib.transforms as mtransforms\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n",
    "                               AutoMinorLocator)\n",
    "colors = {'tp':'#7f58af', 'tc':'#e84d8a', 'iv2' : '#64c5eb', 'pgd' : '#7fb646'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47e4c1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/earthquakes1/homes/Rebecca/phd/data/2018_2021_global_m5/'\n",
    "\n",
    "eq_list = os.listdir(root)\n",
    "\n",
    "cat = obspy.read_events('/home/earthquakes1/homes/Rebecca/phd/data/2018_2021_global_m5_catalog.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0ea7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_with_data = []\n",
    "cat_with_data = cat.copy()\n",
    "cat_with_data.clear()\n",
    "for event in cat:\n",
    "    eq_name = util.catEventToFileName(event)\n",
    "    if os.path.isdir(root+eq_name) and os.path.isdir(root+eq_name+'/station_xml_files') and os.path.exists(root+eq_name+'/picks.pkl'):\n",
    "        eq_with_data.append(eq_name)\n",
    "        cat_with_data.extend([event])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee6db00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tpmax = []\n",
    "list_mags = []\n",
    "list_mag_types = []\n",
    "list_eq = []\n",
    "flinnengdahl_regions = []\n",
    "eqs = {}\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d52da226",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length=0.3; start_window=0; filter_limits=[1,19]; filter_corners=3; blank_time = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43147570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_gen(eq):\n",
    "    plt.close()\n",
    "    data = eq.data\n",
    "    picks = eq.data_stats['picks']\n",
    "    sensor_types = eq.data_stats['sensor_types']\n",
    "    tau_p_list = []\n",
    "    tp_max = []\n",
    "    data_use = []\n",
    "    data_use_unfiltered = []\n",
    "    starts = []\n",
    "    ends = []\n",
    "    #print(data)\n",
    "    for i in range(0, len(data)):  # iterate through all traces\n",
    "        if data[i].stats.channel[2] == 'Z':  # only use vertical components\n",
    "            trace = data[i].copy()\n",
    "            station = trace.stats.station\n",
    "            # station = station.ljust(4)\n",
    "            tr_name = trace.stats.network+'.'+trace.stats.station+'.'+trace.stats.location\n",
    "            if tr_name in picks.keys():\n",
    "                # load saved parameters\n",
    "                sampling_rate = trace.stats.sampling_rate\n",
    "                pick = UTCDateTime(picks[tr_name])\n",
    "                pick_samples = int(round((UTCDateTime(pick) - trace.stats.starttime)*trace.stats.sampling_rate, 0))\n",
    "                snr = max(abs(trace.data[pick_samples:500+pick_samples]))/max(abs(trace.data[pick_samples-700:pick_samples-200]))\n",
    "                if snr > 20:\n",
    "                    # preprocess data\n",
    "                    trace.detrend()\n",
    "                    if sensor_types[i][0] == 'a':\n",
    "                        trace.filter('highpass', freq=filter_limits[0], corners=filter_corners)  # 0.078)#i_freq)\n",
    "                        trace = trace.integrate()\n",
    "                    trace.filter('highpass', freq=filter_limits[0])\n",
    "                    trace.filter('lowpass', freq=filter_limits[1])\n",
    "                    data_use.append(trace.data)\n",
    "                    data_use_unfiltered.append(data[i].data)\n",
    "                    # tr.data[0:int((picks[i] - tr.stats.starttime)*sampling_rate)] = 0\n",
    "                    alpha = 1-(1/sampling_rate)\n",
    "                    x = trace.data\n",
    "                    diff = (trace.differentiate()).data\n",
    "                    X = np.zeros(len(x))\n",
    "                    D = np.zeros(len(x))\n",
    "                    start = int((pick - trace.stats.starttime)*sampling_rate)\n",
    "                    end = int(start + window_length * sampling_rate)\n",
    "                    starts.append(start); ends.append(end)\n",
    "                    for t in range(0, len(trace.data)):\n",
    "                        X[t] = alpha*X[t-1]+x[t]**2\n",
    "                        D[t] = alpha*D[t-1]+diff[t]**2\n",
    "                    tau_p = 2 * np.pi * np.sqrt(X/D)\n",
    "                    tau_p_list.append(tau_p)\n",
    "                    # print(max(tau_p[int(start+0.5*sampling_rate):int(end)]))\n",
    "                    tp_max.append(max(tau_p[int(start+int(blank_time*sampling_rate)):int(end)]))\n",
    "                    #plt.plot(tau_p[pick_samples:int(pick_samples+4*sample_rate)])\n",
    "                    #plt_tp_all = eq.calculated_params['tau_p'][station]\n",
    "                    plt_tp = ((tau_p[int(start):int(end)]))\n",
    "                    #print(tp_max[-1])\n",
    "                    #print(plt_tp)\n",
    "                    plt.plot(plt_tp, color='black')\n",
    "                    #print(eq.calculated_params['tau_p_max'][station])\n",
    "                    #plt.axhline(tp_max[-1], 0, 4*sample_rate)\n",
    "                    #plt.axvspan(0, blank_time*sampling_rate, 0, 1, color='grey',alpha=0.5)\n",
    "                    #print(tp_max[-1])\n",
    "                    #print(tau_p)\n",
    "                    #plt.show()\n",
    "    return tau_p_list, tp_max, data_use, starts, ends, data_use_unfiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb56a4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrum(tr, start, end):\n",
    "    #print(type(tr))\n",
    "    d = obspy.core.trace.Trace()\n",
    "    d.data = np.array(tr)\n",
    "    #plt.close()\n",
    "    #plt.plot(d)\n",
    "    #plt.show()\n",
    "    #d = tr.copy()#.filter('lowpass', freq=10)\n",
    "    #print(type(d))\n",
    "    d.interpolate(100, 'lanczos', a = 20)\n",
    "    d.filter('highpass', freq=0.25) #anything less than 0.25s (1/4s) we can't undertand or model, could be aliased.\n",
    "    d.filter('lowpass', freq = 19)\n",
    "    d.detrend()\n",
    "    d.integrate()\n",
    "    d.detrend()\n",
    "    #print(len(d))\n",
    "    #print(start,end)\n",
    "    coda = obspy.core.trace.Trace()\n",
    "    coda.data = d.data[start:end]\n",
    "    #print(len(coda))\n",
    "    coda.detrend()\n",
    "    #plt.plot(coda)\n",
    "    #plt.show()\n",
    "\n",
    "    dt = d.stats.delta\n",
    "    #print(dt, len(coda))\n",
    "\n",
    "    #creating the frequencies to plot on x axis\n",
    "    Pfreq  = scipy.fft.rfftfreq(len(coda),dt)\n",
    "\n",
    "    #doing the multitaper to get the spectra\n",
    "    N = len(coda)\n",
    "    NW=0.01*N\n",
    "    k=25\n",
    "    [tapers, eigen] = dpss(N, NW, k)\n",
    "    for eigen_no in range(0, len(eigen)):\n",
    "        if eigen[eigen_no] <= 0.5:\n",
    "            k = eigen_no\n",
    "            break\n",
    "    [tapers, eigen] = dpss(N, NW, k)\n",
    "\n",
    "    #print(eigen)\n",
    "    freq_complex, weights, eigenvalues=pmtm(coda, e=eigen, v=tapers, show=False)\n",
    "    freq = abs(freq_complex)\n",
    "    freq = np.mean(freq,axis =0)\n",
    "    freq_sdv = np.std(freq,axis =0)\n",
    "\n",
    "    #plotting the spectra in loglog\n",
    "    #print('plot')\n",
    "\n",
    "    #axs.plot(Pfreq[:-1],freq[0:N//2]-min(freq[0:N//2]), alpha = 0.5, label=str(cat_with_data[eq_no].magnitudes[0].mag), color = cmap[eq_no])#tr_name + data[tr_no].stats.channel)\n",
    "#plt.fill_between(Pfreq[:-1],(Sk+Sk_sdv)[0:N//2],(Sk-Sk_sdv)[0:N//2],alpha=0.2)\n",
    "    #axs.set_xlabel('Frequency (Hz)');\n",
    "    #axs.set_ylabel('A^2');\n",
    "#plt.title(tr_name + data[tr_no].stats.channel+' coda wave Power spectra');\n",
    "#else:\n",
    "    #axs.plot(Pfreq[:-1],freq[0:N//2]-min(freq[0:N//2]), color = cmap[eq_no], alpha = 0.5)#tr_name + data[tr_no].stats.channel)\n",
    "\n",
    "    return Pfreq, freq, N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99df93d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Earthquake' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#print('loaded')\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eq\u001b[38;5;241m.\u001b[39mevent_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meq_mag\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m eq\u001b[38;5;241m.\u001b[39mcalculated_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtau_p\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m!=\u001b[39m[]:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m#print('big')\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     tau_p_list, tp_max, data_use_z, starts, ends, data_use_unfiltered_z \u001b[38;5;241m=\u001b[39m \u001b[43mnew_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m#data_use = []\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m#station = 0\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m#data_station = 0\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(data_use_z)):\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;66;03m#tr = data_use_z[i]\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;66;03m#tr_name = tr.stats.network+'.'+tr.stats.station+'.'+tr.stats.location\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m, in \u001b[0;36mnew_gen\u001b[0;34m(eq)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_gen\u001b[39m(eq):\n\u001b[1;32m      2\u001b[0m     plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m----> 3\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43meq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\n\u001b[1;32m      4\u001b[0m     picks \u001b[38;5;241m=\u001b[39m eq\u001b[38;5;241m.\u001b[39mdata_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpicks\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m     sensor_types \u001b[38;5;241m=\u001b[39m eq\u001b[38;5;241m.\u001b[39mdata_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msensor_types\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Earthquake' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "WINDOW_LENGTH = 0.3\n",
    "%matplotlib inline\n",
    "mosaic = \"\"\"\n",
    "aaa.ccc\n",
    "aaa.ccc\n",
    ".......\n",
    "bbb.ddd\n",
    "bbb.ddd\n",
    ".......\n",
    "eee.ff.\n",
    "eee.ff.\n",
    "....ff.\"\"\"\n",
    "\n",
    "for eq_no in [3]:#range(7, len(eq_with_data)):\n",
    "    blank_samples = 50\n",
    "    print(eq_no)\n",
    "    #try:\n",
    "    #print('loading')\n",
    "    try:\n",
    "        with open('/home/earthquakes1/homes/Rebecca/phd/data/2018_2021_global_m5/'+eq_with_data[eq_no]+'/eq_object_1s_bandpass_01_19_snr_20.pkl', 'rb') as picklefile:\n",
    "            eq = pickle.load(picklefile)\n",
    "    except:\n",
    "        continue\n",
    "    #for num_station in range(0, len(eq.calculated_params['tau_p_max'])):\n",
    "        #distance = eq.calculated_params['iv2'][num_station][1]\n",
    "        data = obspy.read(root+eq_with_data[eq_no]+'/data/*/*')\n",
    "    #print('loaded')\n",
    "    if eq.event_stats['eq_mag'] > 5 and eq.calculated_params['tau_p']!=[]:\n",
    "        #print('big')\n",
    "        tau_p_list, tp_max, data_use_z, starts, ends, data_use_unfiltered_z = new_gen(eq)\n",
    "        #data_use = []\n",
    "        #station = 0\n",
    "        #data_station = 0\n",
    "        for i in range(0, len(data_use_z)):\n",
    "            #tr = data_use_z[i]\n",
    "            #tr_name = tr.stats.network+'.'+tr.stats.station+'.'+tr.stats.location\n",
    "\n",
    "            fig = plt.figure(constrained_layout=True,figsize=(12,9))\n",
    "            ax = fig.add_subplot(111, frameon=False)\n",
    "            plt.tick_params(labelcolor='none', which='both', top=False, bottom=False, left=False, right=False)\n",
    "\n",
    "            ax.add_patch(Rectangle((0.0, 0.02), 0.46, 0.315,\n",
    "            fc='lightgreen',\n",
    "            color ='#00cd6c',\n",
    "            linewidth = 1,\n",
    "            alpha = 0.5))\n",
    "\n",
    "            ax_dict = fig.subplot_mosaic(mosaic)\n",
    "\n",
    "\n",
    "\n",
    "            #identify_axes(ax_dict)\n",
    "            #x = np.arange(-100,4*sample_rate,1)\n",
    "            ax_dict['a'].plot(data_use_z[i][starts[i]:ends[i]], color='k')\n",
    "\n",
    "            to_diff = obspy.core.trace.Trace()\n",
    "            to_diff.data = data_use_z[i]\n",
    "            diffed = (to_diff.differentiate()).data\n",
    "            ax_dict['b'].plot(diffed[starts[i]:ends[i]], color = 'k')\n",
    "\n",
    "            ax_dict['c'].plot(tau_p_list[i][starts[i]:ends[i]], color='k')\n",
    "            #print(np.argmax(tau_p_list[i][starts[i]+blank_samples:ends[i]])+blank_samples)\n",
    "            #print(np.max(tau_p_list[i][starts[i]+50:ends[i]]))\n",
    "            ax_dict['c'].scatter(np.argmax(tau_p_list[i][starts[i]+blank_samples:ends[i]])+blank_samples, np.max(tau_p_list[i][starts[i]+50:ends[i]]), color = colors['tp'])\n",
    "            ax_dict['c'].axvspan(blank_samples,ends[i]-starts[i], color = colors['tp'], alpha = 0.1)\n",
    "            #axs[1].plot(x, eq.calculated_params['tau_p'][station][pick_samples-100:int(pick_samples+4*sample_rate)])\n",
    "\n",
    "            squared = data_use_z[i][starts[i]:ends[i]]**2\n",
    "            ax_dict['d'].plot(squared, color='k')\n",
    "            ax_dict['d'].fill_between(np.arange(0,len(squared),1),squared, alpha = 0.5, color = colors['iv2'])\n",
    "\n",
    "            ax_dict['e'].plot(abs(diffed[starts[i]:ends[i]]), color = 'k')\n",
    "            ax_dict['e'].scatter(np.argmax(abs(diffed[starts[i]:ends[i]])), np.max(abs(diffed[starts[i]:ends[i]])), color = colors['pgd'])\n",
    "            ax_dict['e'].axvspan(blank_samples,ends[i]-starts[i], color = '#009ade', alpha = 0.1)\n",
    "            #axs[1].plot(x, eq.calculated_params['tau_p'][station][pick_samples-100:int(pick_samples+4*sample_rate)])\n",
    "\n",
    "\n",
    "            #print(type(data_use_z))\n",
    "            Pfreq, freq, N = spectrum(data_use_unfiltered_z[i],starts[i],ends[i])\n",
    "            ax_dict['f'].plot(Pfreq[:-1],freq[0:N//2]-min(freq[0:N//2]), color='black')\n",
    "            ax_dict['f'].set_xscale('log')\n",
    "            ax_dict['f'].set_yscale('log')\n",
    "\n",
    "\n",
    "\n",
    "            #JOINING ARROWS\n",
    "            ax.annotate(\"\",\n",
    "            xy=(0.55, 0.9), xycoords='data',\n",
    "            xytext=(0.45, 0.9), textcoords='data',\n",
    "            arrowprops=dict(arrowstyle=(\"simple, head_width=1.5, head_length=2, tail_width = 0.5\"),\n",
    "                            connectionstyle=\"arc3\",color='grey'),)\n",
    "            ax.annotate(\"\",\n",
    "            xy=(0.55, 0.65), xycoords='data',\n",
    "            xytext=(0.45, 0.78), textcoords='data',\n",
    "            arrowprops=dict(arrowstyle=(\"simple, head_width=1.5, head_length=2, tail_width = 0.5\"),\n",
    "                            connectionstyle=\"arc3\",color='grey'),)\n",
    "            ax.annotate(\"\",\n",
    "            xy=(0.57, 0.31), xycoords='data',\n",
    "            xytext=(0.45, 0.45), textcoords='data',\n",
    "            arrowprops=dict(arrowstyle=(\"simple, head_width=1.5, head_length=2, tail_width = 0.5\"),\n",
    "                            connectionstyle=\"arc3\",color='grey'),)\n",
    "            ax.annotate(\"\",\n",
    "            xy=(0.24, 0.67), xycoords='data',\n",
    "            xytext=(0.24, 0.76), textcoords='data',\n",
    "            arrowprops=dict(arrowstyle=(\"simple, head_width=1.5, head_length=2, tail_width = 0.5\"),\n",
    "                            connectionstyle=\"arc3\",color='grey'),)\n",
    "            ax.annotate(\"\",\n",
    "            xy=(0.24, 0.34), xycoords='data',\n",
    "            xytext=(0.24, 0.42), textcoords='data',\n",
    "            arrowprops=dict(arrowstyle=(\"simple, head_width=1.5, head_length=2, tail_width = 0.5\"),\n",
    "                            connectionstyle=\"arc3\",color='grey') )\n",
    "\n",
    "            ax2 = fig.add_subplot(111, frameon=False)\n",
    "            plt.tick_params(labelcolor='none', which='both', top=False, bottom=False, left=False, right=False)\n",
    "\n",
    "\n",
    "            #ANNOTATION ARROWS\n",
    "            ax2.annotate(\"\",\n",
    "            xy=(0.85, 0.41), xycoords='data',\n",
    "            xytext=(0.65, 0.41), textcoords='data',\n",
    "            arrowprops=dict(arrowstyle=(\"simple, head_width=1.5, head_length=1.5, tail_width = 0.5\"),\n",
    "                           connectionstyle=\"arc3\", color = '#ffc61e'),)\n",
    "\n",
    "\n",
    "            x = (np.argmax(tau_p_list[i][starts[i]+blank_samples:ends[i]])+blank_samples)\n",
    "            y = (np.max(tau_p_list[i][starts[i]+blank_samples:ends[i]]))\n",
    "            ax_dict['c'].annotate(\"\",\n",
    "                        xy=(x, y), xycoords='data',\n",
    "                        xytext=(0.75, 0.8), textcoords='axes fraction',color=colors['tp'],\n",
    "                        arrowprops=dict(arrowstyle=(\"simple, head_width=1.5, head_length=1.5, tail_width = 0.5\"),\n",
    "                           connectionstyle=\"arc3\", color = '#009ade'),)\n",
    "\n",
    "            ax_dict['c'].annotate(\"maximum in \\ntime window\\n --> \"+r\"$\\tau _p ^{max}$\",\n",
    "                        xy=(x, y), xycoords='data',\n",
    "                        xytext=(0.75, 0.62), textcoords='axes fraction',fontsize=12)\n",
    "\n",
    "            x= [np.argmax(abs(diffed[starts[i]:ends[i]]))]\n",
    "            y = [np.max(abs(diffed[starts[i]:ends[i]]))]\n",
    "            ax_dict['e'].annotate(\"\",\n",
    "                        xy=(x, y), xycoords='data',\n",
    "                        xytext=(0.75, 0.8), textcoords='axes fraction',color=colors['pgd'],\n",
    "                        arrowprops=dict(arrowstyle=(\"simple, head_width=1.5, head_length=1.5, tail_width = 0.5\"),\n",
    "                           connectionstyle=\"arc3\", color = '#009ade'),)\n",
    "\n",
    "            ax_dict['e'].annotate(\"maximum in \\ntime window\\n --> \"+r\"$P_{D}$\",\n",
    "                        xy=(x, y), xycoords='data',\n",
    "                        xytext=(0.75, 0.62), textcoords='axes fraction',fontsize=12)\n",
    "\n",
    "            ax_dict['f'].annotate(\"\",\n",
    "                        xy=(0.4, 0.1), xycoords='axes fraction',\n",
    "                        xytext=(0.1, 0.1), textcoords='axes fraction',color=colors['tc'],\n",
    "                        arrowprops=dict(arrowstyle=(\"simple, head_width=1.5, head_length=1.5, tail_width = 0.5\"),\n",
    "                           connectionstyle=\"arc3\", color = '#af58ba'),)\n",
    "\n",
    "            ax_dict['f'].annotate(\"weighted average \\nof frequency \\n --> average period (eqn 10)\",\n",
    "                        xy=(0.1, 0.15), xycoords='axes fraction',\n",
    "                        xytext=(0.1, 0.15), textcoords='axes fraction',color='black',fontsize=12)\n",
    "\n",
    "            #TEXT ANNOTATIONS\n",
    "\n",
    "            ax.annotate(\"calculate\"+r\"$\\tau _p$\",\n",
    "            xy=(0.5, 0.92), xycoords='data',\n",
    "            xytext=(0.47, 0.92), textcoords='data',fontsize=12)\n",
    "\n",
    "            ax.annotate(\"integrate\",\n",
    "            xy=(0.26, 0.71), xycoords='data',\n",
    "            xytext=(0.26, 0.71), textcoords='data',fontsize=12)\n",
    "\n",
    "            ax.annotate(\"take \\nabsolute \\nvalue\",\n",
    "            xy=(0.26, 0.36), xycoords='data',\n",
    "            xytext=(0.26, 0.35), textcoords='data',fontsize=12)\n",
    "\n",
    "            ax.annotate(\"square\",\n",
    "            xy=(0.51, 0.73), xycoords='data',\n",
    "            xytext=(0.51, 0.73), textcoords='data',fontsize=12)\n",
    "\n",
    "            ax.annotate(\"take the \\nspectrum\",\n",
    "            xy=(0.51, 0.39), xycoords='data',\n",
    "            xytext=(0.51, 0.39), textcoords='data',fontsize=12)\n",
    "\n",
    "            # ax.annotate(\"\",\n",
    "            # xy=(0.05, 0.05), xycoords='data',\n",
    "            # xytext=(0.05, 0.03), textcoords='data',fontsize=12)\n",
    "\n",
    "            ax2.annotate(\"integrate --> IV2\",\n",
    "            xy=(0.69, 0.38), xycoords='data',\n",
    "            xytext=(0.69, 0.38), textcoords='data',fontsize=12)\n",
    "\n",
    "            ax3 = fig.add_subplot(111, frameon=False)\n",
    "            plt.tick_params(labelcolor='none', which='both', top=False, bottom=False, left=False, right=False)\n",
    "\n",
    "            #x = np.argmin(tau_p_list[i][starts[i]+blank_samples:ends[i]])+blank_samples\n",
    "            #y = np.max(tau_p_list[i][starts[i]+blank_samples:ends[i]])\n",
    "            #x, y = 0,0\n",
    "            #ax3.annotate(\"text\",\n",
    "            #            xy=(x+0.57, y+0.77), xycoords='data',\n",
    "            #            xytext=(1, 1), textcoords='data',color='blue',\n",
    "            #arrowprops=dict(arrowstyle=(\"simple, head_width=1.5, head_length=2, tail_width = 0.5\"),\n",
    "            #               connectionstyle=\"arc3\", color = 'orange'),zorder= 10000) # where is this arrow????????\n",
    "            label_list = ['a)','d)','b)','e)','c)','f)']\n",
    "            label_count = 0\n",
    "            for label, ax in ax_dict.items():\n",
    "                # label physical distance to the left and up:\n",
    "                trans = mtransforms.ScaledTranslation(-20/72, 7/72, fig.dpi_scale_trans)\n",
    "                ax.text(0.0, 1.0, label_list[label_count], transform=ax.transAxes + trans,\n",
    "                fontsize='medium', va='bottom')\n",
    "                label_count += 1\n",
    "            ax_dict['a'].set_xlabel('time (s)', horizontalalignment='right',x=1)\n",
    "            ax_dict['b'].set_xlabel('time (s)', horizontalalignment='right',x=1)\n",
    "            ax_dict['c'].set_xlabel('time (s)', horizontalalignment='right',x=1)\n",
    "            ax_dict['d'].set_xlabel('time (s)', horizontalalignment='right',x=1)\n",
    "            ax_dict['e'].set_xlabel('time (s)', horizontalalignment='right',x=1)\n",
    "            ax2.set_xlabel('log(frequency)', x=0.87)\n",
    "\n",
    "            ax_dict['a'].set_title('Velocity seismogram',fontsize=14)\n",
    "            ax_dict['b'].set_title('Displacement seismogram',fontsize=14)\n",
    "            ax_dict['c'].set_title('2.1 Predominant period',fontsize=14)\n",
    "            ax_dict['d'].set_title('2.4 IV2',fontsize=14)\n",
    "            ax_dict['e'].set_title('2.3 Peak ground displacement',fontsize=14)\n",
    "            ax_dict['f'].set_title('2.2 Average period',fontsize=14)\n",
    "\n",
    "            ax_dict['a'].set_ylabel('Velocity ($ms^{-1}$)')\n",
    "            ax_dict['b'].set_ylabel('Displacement (m)')\n",
    "            ax_dict['c'].set_ylabel('Predominant period')\n",
    "            ax_dict['d'].set_ylabel('Velocity squared ($m^2s^{-2}$)')\n",
    "            ax_dict['e'].set_ylabel('Absolute displacement (m)')\n",
    "            ax_dict['f'].set_ylabel('log(amplitude)')\n",
    "\n",
    "            ax_dict['a'].set_xticks(np.linspace(0, ends[i]-starts[i],5), [0,1,2,3,4])\n",
    "            ax_dict['b'].set_xticks(np.linspace(0, ends[i]-starts[i],5), [0,1,2,3,4])\n",
    "            ax_dict['c'].set_xticks(np.linspace(0, ends[i]-starts[i],5), [0,1,2,3,4])\n",
    "            ax_dict['d'].set_xticks(np.linspace(0, ends[i]-starts[i],5), [0,1,2,3,4])\n",
    "            ax_dict['e'].set_xticks(np.linspace(0, ends[i]-starts[i],5), [0,1,2,3,4])\n",
    "\n",
    "\n",
    "            #ax2.annotate(\"Frequency (Hz)\",\n",
    "            #xy=(0.05, 0.), xycoords='data',\n",
    "            #xytext=(0.85, 0.), textcoords='axes fraction')\n",
    "\n",
    "            #ax_dict['f'].set_xlabel('frequency (Hz)', horizontalalignment='right',x=1)\n",
    "            print(str(eq_no)+'_'+str(i))\n",
    "            #plt.savefig('/home/earthquakes1/homes/Rebecca/phd/figures/method_summary_figs/'+eq_with_data[eq_no]+'_'+tr_name)\n",
    "            #plt.savefig('/home/earthquakes1/homes/Rebecca/phd/figures/method_summary_figs/'+eq_with_data[eq_no]+'_'+str(i),format = 'pdf')\n",
    "            plt.show()\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        print('small')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51c16bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0., 100., 200., 300., 400.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0, ends[i]-starts[i],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdacd588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
