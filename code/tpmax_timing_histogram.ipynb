{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import obspy\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "from scipy.optimize import curve_fit\n",
    "from datetime import timedelta\n",
    "from obspy import UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "\n",
    "from earthquake import Earthquake\n",
    "import util\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get set up\n",
    "Set path to data, and read eq_list (all folders in root folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/earthquakes1/homes/Rebecca/phd/data/2019_global_m3/'\n",
    "\n",
    "eq_list = os.listdir(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open catalog of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(\"IRIS\")\n",
    "# cat = client.get_events(starttime=UTCDateTime(\"2019-01-01\"), endtime=UTCDateTime(\"2020-01-01\"), minmagnitude=5, includearrivals=True)\n",
    "cat = obspy.read_events('/home/earthquakes1/homes/Rebecca/phd/data/2019_global_m3_catalog.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all events had suitable data, look through all events and make a list of ones which have data (eq_with_data) and were successfully picked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_with_data = []\n",
    "cat_with_data = cat.copy()\n",
    "cat_with_data.clear()\n",
    "for event in cat:\n",
    "    eq_name = util.catEventToFileName(event)\n",
    "    if os.path.isdir(root+eq_name) and os.path.isdir(root+eq_name+'/station_xml_files') and os.path.exists(root+eq_name+'/picks.pkl'):\n",
    "        eq_with_data.append(eq_name)\n",
    "        cat_with_data.extend([event])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the action!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find location of tpmax in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(\"IRIS\")\n",
    "# cat = client.get_events(starttime=UTCDateTime(\"2019-01-01\"), endtime=UTCDateTime(\"2020-01-01\"), minmagnitude=5, includearrivals=True)\n",
    "cat = obspy.read_events('/home/earthquakes1/homes/Rebecca/phd/data/2019_global_m3_catalog.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6075\n"
     ]
    }
   ],
   "source": [
    "eq_with_data = []\n",
    "cat_with_data = cat.copy()\n",
    "cat_with_data.clear()\n",
    "for event in cat:\n",
    "    eq_name = util.catEventToFileName(event)\n",
    "    if os.path.isdir(root+eq_name) and os.path.isdir(root+eq_name+'/station_xml_files') and os.path.exists(root+eq_name+'/picks.pkl'):\n",
    "        eq_with_data.append(eq_name)\n",
    "        cat_with_data.extend([event])\n",
    "print(len(eq_with_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Earthquake' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3688496/1091821229.py\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculated_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tau_p_max'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstation\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'picks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;31m#print(eq.data[i*3].stats.network+'.'+eq.data[i*3].stats.station+'.'+eq.data[i*3].stats.location)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Earthquake' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "%matplotlib qt \n",
    "WINDOW_LENGTH = 4\n",
    "diff = []\n",
    "for eq_no in range(0, 10):#len(eq_with_data)):\n",
    "    print(eq_no)\n",
    "    with open('/home/earthquakes1/homes/Rebecca/phd/data/2019_global_m3/'+eq_with_data[eq_no]+'/eq_object.pkl', 'rb') as picklefile:\n",
    "        eq = pickle.load(picklefile)\n",
    "        keys = list(eq.data_stats['picks'].keys())\n",
    "        for i in range(len(eq.calculated_params['tau_p_max'])):\n",
    "            name = eq.calculation_info[\"tau_p_stations\"][i]\n",
    "            if name in eq.data_stats['picks'].keys():\n",
    "                pick = (eq.data_stats['picks'][name]-eq.data[i*3+2].stats.starttime)*eq.data[i*3+2].stats.sampling_rate\n",
    "                #plt.plot(eq.calculated_params['tau_p'][i])\n",
    "                #plt.axhline(eq.calculated_params['tau_p_max'][i], 0, 1000)\n",
    "                #plt.show()\n",
    "                pick_seconds = pick / (eq.data[i*3].stats['sampling_rate'])\n",
    "                a = np.where(eq.calculated_params['tau_p'][i][int(pick):]==eq.calculated_params['tau_p_max'][i])\n",
    "                if len(a[0])>0:\n",
    "                    max_loc = a[0][0]* 100/(eq.data[i*3+2].stats['sampling_rate'])+pick * 100/(eq.data[i*3+2].stats['sampling_rate'])\n",
    "                    #print(eq.data[i*3])\n",
    "                    if abs(max_loc-pick* 100/(eq.data[i*3+2].stats['sampling_rate'])) < 4 * eq.data[i*3].stats['sampling_rate']:\n",
    "                        #eq.data[i*3+2].plot()\n",
    "                        #plt.plot(eq.calculated_params['tau_p'][i][int(pick):])\n",
    "                        #plt.axhline(eq.calculated_params['tau_p_max'][i], 0, 1000)\n",
    "                        #plt.show()\n",
    "                        #print(i)\n",
    "                        #print(eq.calculated_params['tau_p_max'][i])\n",
    "                        #print(max(eq.calculated_params['tau_p'][i][int(pick)+50:int(pick)+400]))\n",
    "                        #print(eq.data[i*3+2].stats.sampling_rate)\n",
    "                        #print(pick)\n",
    "                        #print(max_loc)\n",
    "                        #print(max_loc-pick* 100/(eq.data[i*3].stats['sampling_rate']))\n",
    "                        diff.append((max_loc-pick*100/(eq.data[i*3].stats['sampling_rate']))/100)\n",
    "    #list_tpmax.append(eq.calculated_params['tau_p_max'])\n",
    "\n",
    "    #except Exception:\n",
    "    #    print('in except')\n",
    "    #    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(diff, np.arange(0, 4, 0.1))\n",
    "plt.ylabel('time from pick')\n",
    "plt.xlabel('n')\n",
    "plt.title('timing of tpmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.36418575,  0.36451736,  0.36515183, ...,  4.57211618,\n",
       "        4.55904055,  4.54593945])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq.calculated_params['tau_p'][i][int(pick):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53657723300601767"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq.calculated_params['tau_p_max'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'event_stats': {'name': '20190131_194949.a',\n",
       "  'eq_lat': -20.4865,\n",
       "  'eq_long': -69.0165,\n",
       "  'eq_depth': 102120.0,\n",
       "  'eq_mag': 4.2,\n",
       "  'eq_mag_type': 'mb'},\n",
       " 'event': Event:\t2019-01-31T19:49:49.660000Z | -20.486,  -69.016 | 4.2  mb\n",
       "\n",
       "\t            resource_id: ResourceIdentifier(id=\"smi:service.iris.edu/fdsnws/event/1/query?eventid=11001567\")\n",
       "\t             event_type: 'earthquake'\n",
       "\t    preferred_origin_id: ResourceIdentifier(id=\"smi:service.iris.edu/fdsnws/event/1/query?originid=36907036\")\n",
       "\t preferred_magnitude_id: ResourceIdentifier(id=\"smi:service.iris.edu/fdsnws/event/1/query?magnitudeid=192541937\")\n",
       "\t                   ---------\n",
       "\t     event_descriptions: 1 Elements\n",
       "\t                origins: 1 Elements\n",
       "\t             magnitudes: 1 Elements,\n",
       " 'data_stats': {'picks': {'CX.PB08.': 2019-01-31T19:50:06.058394Z,\n",
       "   'CX.PB01.': 2019-01-31T19:50:08.498393Z,\n",
       "   'CX.HMBCX.': 2019-01-31T19:50:09.489999Z},\n",
       "  'sensor_types': ['VEL',\n",
       "   'VEL',\n",
       "   'VEL',\n",
       "   'VEL',\n",
       "   'VEL',\n",
       "   'VEL',\n",
       "   'VEL',\n",
       "   'VEL',\n",
       "   'VEL']},\n",
       " 'inv': Inventory created at 2021-10-28T15:56:51.413805Z\n",
       "\tSending institution: SeisComP (GFZ)\n",
       "\tContains:\n",
       "\t\tNetworks (3):\n",
       "\t\t\tCX (3x)\n",
       "\t\tStations (3):\n",
       "\t\t\tCX.HMBCX (IPOC Station Humberstone, Chile)\n",
       "\t\t\tCX.PB01 (IPOC Station Huatacondo, Chile)\n",
       "\t\t\tCX.PB08 (IPOC Station Macaya, Chile)\n",
       "\t\tChannels (9):\n",
       "\t\t\tCX.HMBCX..HHZ, CX.HMBCX..HHN, CX.HMBCX..HHE, CX.PB01..HHZ, \n",
       "\t\t\tCX.PB01..HHN, CX.PB01..HHE, CX.PB08..HHZ, CX.PB08..HHN, \n",
       "\t\t\tCX.PB08..HHE,\n",
       " 'calculated_params': {'iv2': [[9.924117644452447e-10, 98.55508587916829],\n",
       "   [5.695135479130604e-09, 80.20916870963086],\n",
       "   [7.620385895086197e-09, 40.86747298573802]],\n",
       "  'tau_c': [0.2682018971852354, 0.1908354211956681, 0.31900362525925935],\n",
       "  'tau_p': [array([0.        , 0.01595446, 0.03253336, ..., 4.57211618, 4.55904055,\n",
       "          4.54593945]),\n",
       "   array([0.        , 0.01558898, 0.03181872, ..., 4.96500506, 4.96464423,\n",
       "          4.964326  ]),\n",
       "   array([0.        , 0.01629953, 0.03328788, ..., 4.62944402, 4.62926846,\n",
       "          4.62903098])],\n",
       "  'tau_p_max': [0.5365772330060177, 0.4431244896546434, 0.4023951983845566]}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq.__dict__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
